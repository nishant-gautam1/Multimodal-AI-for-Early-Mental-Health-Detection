# Quick Start Guide - Text & Image Modules

## ğŸ“ Text Module - Production Scripts

### What Was Created
âœ… 4 new Python scripts in `text_module/src/`:
- `text_utils.py` - Utility functions
- `text_preprocessing.py` - Data preprocessing
- `train_text_model.py` - BERT training
- `evaluate_text.py` - Model evaluation

### Quick Start
```bash
cd text_module

# 1. Preprocess data
python src/text_preprocessing.py

# 2. Train BERT model
python src/train_text_model.py

# 3. Evaluate model
python src/evaluate_text.py

# 4. Run existing Flask API
python flask_app/text_model.py
```

### Requirements
- Dataset: `data/Combined_Data_Expanded.csv` (not in repo)
- GPU recommended (8GB+ VRAM)
- Training time: ~30-60 min (GPU), ~2-4 hours (CPU)

---

##  Audio Module - Complete Implementation

### What Was Created
âœ… 4 new Python scripts in audio_module/src/ (plus model and Flask demo):
   - `audio_utils.py` â€” Utility functions (I/O, resampling, feature helpers)
   - `preprocessing.py` â€” Audio preprocessing & MFCC / feature extraction
   - `train_audio_model_lstm.py` â€” LSTM training script (saves audio_lstm_model.h5)
   - `evaluate.py` â€” Model evaluation & metrics

### Quick Start
```bash
cd audio_module

# 1. Install dependencies
pip install -r requirements.txt

# 2. Prepare dataset
# Place audio files under: audio_module/data/raw/
# (Maintain folder structure expected by preprocessing.py; typically class subfolders or a CSV mapping)

# 3. Preprocess audio and extract features (MFCCs)
python src/preprocessing.py

# 4. Train LSTM audio model
python src/train_audio_model_lstm.py

# 5. Evaluate model
python src/evaluate.py

# 6. Run existing Flask API for demo/inference
python flask_app/app_audio.py
# Then visit or query the endpoint (check app_audio.py for exact route and port)
```

### Requirements
- Dataset: audio files (not included) â€” put under audio_module/data/raw/ (or follow README instructions)
- Python packages: see audio_module/requirements.txt (typical: librosa, soundfile, numpy, scikit-learn, tensorflow or torch, flask)
- GPU recommended (8GB+ VRAM) for faster training
- Training time: ~30â€“90 minutes (GPU), ~2â€“4 hours (CPU) â€” depends on dataset size & hyperparameters

### Model files (existing / expected locations)
- audio_module/model/audio_lstm_model.h5 â€” trained LSTM model (Keras .h5)
- audio_module/model/audio_label_encoder.pkl â€” label encoder for classes
  
---

## ğŸ¯ Key Features

### Text Module
- âœ… Production-ready scripts (no Jupyter dependency)
- âœ… BERT fine-tuning with HuggingFace
- âœ… 7-class mental health classification
- âœ… Compatible with existing Flask API

### Image Module
- âœ… MFCC + spectral features (MFCC, delta, chroma, spectral centroid)
- âœ… LSTM-based sequence model (saved as model/audio_lstm_model.h5)
- âœ… Audio preprocessing (resampling, mono, noise reduction, silence trimming)
- âœ… Data augmentation (time-stretch, pitch-shift, noise injection)
- âœ… On-device feature normalization & fixed-length framing for LSTM input
- âœ… Flask REST API (flask_app/app_audio.py) â€” default port 5000 (check file)
- âœ… Demo UI template for uploading .wav files (multipart/form-data)
- âœ… 3-class mental-health classification (labels in model/audio_label_encoder.pkl)

---

## ğŸ“Š Module Comparison

| Feature | Audio | Text | 
|---------|-------|------|
| **Status** | âœ… Complete | âœ… Enhanced | 
| **Model** | LSTM | BERT | CNN |
| **Input** | .wav files | Text strings | 
| **Classes** | 3 | 7 | 
| **Port** | 5000 | 5000 | 

---



## ğŸ“ File Locations

### Text Module
```
text_module/src/
â”œâ”€â”€ text_utils.py             
â”œâ”€â”€ text_preprocessing.py      
â”œâ”€â”€ train_text_model.py       
â””â”€â”€ evaluate_text.py           
```

### Audio Module
```
audio_module/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/         # audio files or dataset subfolders
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ audio_utils.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”œâ”€â”€ train_audio_model.py
â”‚   â””â”€â”€ evaluate_audio.py
â””â”€â”€ flask_app/
    â””â”€â”€ audio_model.py
```

---

## âš ï¸ Important Notes

- **Datasets are not included** â€” You must manually place the required files in each moduleâ€™s data folder.
- **Preprocessing is required before training** â€” Both text and audio pipelines depend on processed outputs generated by their respective preprocessing scripts.
- **GPU strongly recommended** â€” BERT (text) and LSTM (audio) training are slow on CPU; at least 8GB VRAM is suggested.
- **Model artifacts are auto-saved** â€” Ensure `models/` (text) and `model/` (audio) folders exist for saving weights and label encoders.
- **APIs require trained models** â€” Run training first; otherwise the Flask apps cannot load model files.
- **Keep file paths consistent** â€” Incorrect or missing paths will cause preprocessing, training, or API loading errors.
---

